# spider
爬取京东商品数据
2.说明文档

本程序主要逻辑：首先通过爬取模块输入所需要爬取的网页，对数据进行爬取，将爬取数据转换成.csv文件保存在数据文件夹中，然后通过写入模块将数据文件夹中数据进行读取写入数据库，当数据库数据写入完成，我们可以通过清洗模块对数据进行清洗，并更新数据库。 所以主要分为三个模块：数据爬取模块、数据清洗模块、数据写入模块。
2.1 数据爬取模块
首先通过webdrive.chrome驱动加载京东网页（本程序所使用的为chrome浏览器），由于需要对商品进行搜索，需要对首页输入框进行输入查找两个操作，所以要定义一个搜索商品的方法Get_product(keyword)，通过在控制台输入所要爬取的商品名称，调用Get_product(keyword)实现对首页输入框的字符输入和点击首页搜索商品。当商品搜索完成后，出现商品展示页面，需要调用drop_down()方法，对网页进行向下滑动，解决网页懒加载问题，同时需要进入页面的开发模式，查找所需要的商品数据元素值，将元素值复制到parse_data()方法中，对元素进行爬取，并将文件以。Csv的文本形式保存在特定的文件夹中，最后通过Get_next（）方法对页面进行翻页处理，重复parse_data()方法进行内容爬取。
2.2数据写入模块
	数据写入模块较为简单，首先定义一个定义一个地址变量，指向数据爬取模块中数据所存放的数据库，使用os模块对文件夹下所有的csv文件进行遍历，使用pandas模块中dict.read_csv(file_name,names=['列名1','列名1','列名3‘, ‘列名4'])，对文件进行读取并为数据添加列属性值，之后实体化数据库引擎，使用dict_to_sql()将数据写入相应数据库。
2.3数据清洗模块
	数据清洗模块，主要是对我们爬取下来的数据进行清洗，使数据变为我们需要的数据形式。本程序主要对数据进行一下操作：
1）. 删除数据表中重复的数值
2）. 对空值数据进行删除
3）. 对数据进行分组****在数据表的价格字段记录了电脑价格，这里我们可以根据价格的多少对上商品进行分级
4）. 首先将评论中字符’+‘给去除，然后将’万‘转换成10000，最后将数据从text类型转化成int类型进行处理
